{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e5803d",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- 빈 코드를 완성하여 제출합니다.\n",
    "- 제출 파일명은 \"과제2_학번_이름.ipynb\" 입니다.\n",
    "- random_state 를 지정할 수 있는 함수 및 메소드에 대해, 321으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3456d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acfbcd",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d00624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>10.490</td>\n",
       "      <td>18.61</td>\n",
       "      <td>66.86</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.02297</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>...</td>\n",
       "      <td>11.06</td>\n",
       "      <td>24.54</td>\n",
       "      <td>70.76</td>\n",
       "      <td>375.4</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.06528</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.07842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>14.270</td>\n",
       "      <td>22.55</td>\n",
       "      <td>93.77</td>\n",
       "      <td>629.8</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.11540</td>\n",
       "      <td>0.14630</td>\n",
       "      <td>0.06139</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.05982</td>\n",
       "      <td>...</td>\n",
       "      <td>15.29</td>\n",
       "      <td>34.27</td>\n",
       "      <td>104.30</td>\n",
       "      <td>728.3</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.42340</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.08351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>9.731</td>\n",
       "      <td>15.34</td>\n",
       "      <td>63.78</td>\n",
       "      <td>300.2</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.41080</td>\n",
       "      <td>0.07857</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.09296</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>19.49</td>\n",
       "      <td>71.04</td>\n",
       "      <td>380.5</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.82160</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.12590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "303       10.490         18.61           66.86      334.3           0.1068   \n",
       "536       14.270         22.55           93.77      629.8           0.1038   \n",
       "152        9.731         15.34           63.78      300.2           0.1072   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "303           0.06678         0.02297              0.01780         0.1482   \n",
       "536           0.11540         0.14630              0.06139         0.1926   \n",
       "152           0.15990         0.41080              0.07857         0.2548   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "303                 0.06600  ...         11.06          24.54   \n",
       "536                 0.05982  ...         15.29          34.27   \n",
       "152                 0.09296  ...         11.02          19.49   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "303            70.76       375.4            0.1413             0.1044   \n",
       "536           104.30       728.3            0.1380             0.2733   \n",
       "152            71.04       380.5            0.1292             0.2772   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "303          0.08423               0.06528          0.2213   \n",
       "536          0.42340               0.13620          0.2698   \n",
       "152          0.82160               0.15710          0.3108   \n",
       "\n",
       "     worst fractal dimension  \n",
       "303                  0.07842  \n",
       "536                  0.08351  \n",
       "152                  0.12590  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.sample(3, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f066d",
   "metadata": {},
   "source": [
    "## 0. 데이터 분할\n",
    "- cancer.data 를 입력 특징으로, cancer.target을 타겟 변수로 하여 학습 데이터와 테스트 데이터를 분할합니다.\n",
    "- 테스트 데이터 비율은 20% 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be520de2-d088-4df5-8341-4174ffcccee2",
   "metadata": {},
   "source": [
    "#### ppt 11 클래스 분류 참조\n",
    "* train_test_split 함수: 랜덤하게 데이터 분할\n",
    "* 학습 데이터: 80%, 테스트 데이터: 20%\n",
    "* random_state: 데이터를 무작위로 섞을 때 사용되는 시드 값\n",
    "    * 시드 값이 같다면 train_test_split 함수는 항상 같은 방식으로 데이터를 섞어 같은 결과 생성 -> 재현 가능한 결과 얻을 수 있음\n",
    "    * 일반적으로 0 or 양의 정수, 특별한 경우 제외하고는 별로 큰 의미 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3e1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_df, cancer.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a418c4",
   "metadata": {},
   "source": [
    "## 1. 결정 트리\n",
    "- 결정 트리 모델을 학습하고, 학습 및 테스트 데이터에 각각에 대해 정확도 및 F1을 측정합니다.\n",
    "- 1-1. 제약 없는 결정 트리를 entropy 를 불순도 지표로 사용하여 학습합니다. \n",
    "- 1-2. 트리 최대 깊이를 3으로 지정한 가지치기한 결정 트리를 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa1403-b696-4fd9-b570-9b925b32ad02",
   "metadata": {},
   "source": [
    "#### ppt 11 참조\n",
    "- DecisionTreeClassifier: 결정 트리 생성\n",
    "- f1: 모델이 얼마나 잘 분류하는지 종합적으로 평가하는 지표\n",
    "    - 정밀도와 재현율의 조화 평균으로 계산\n",
    "    - 클래스 불균형 문제를 다룰 때 유용\n",
    "####\n",
    "- criterion: 결정 트리 모델에서 노드를 분할하는데 사용되는 기준을 지정하는데 사용\n",
    "    - entropy: 정보 이론에서 불확실성의 정도를 나타내는 척도\n",
    "        - entropy가 낮을 수록 데이터의 순도(purity) 높아짐\n",
    "    - gini: entropy처럼 불확실성을 측정하는 지표, 노드의 순도 측정\n",
    "        - gini 불순도가 낮을 수록 해당 노드의 순도가 높아짐\n",
    "- fit(입력 데이터, 타겟 데이터): 입력 데이터를 사용하여 결정 트리 모델을 학습시키는 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe14bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 제약없는 결정 트리 =\n",
      "(학습) 정확도: 1.000\n",
      "(학습) F1: 1.000\n",
      "(테스트) 정확도: 0.947\n",
      "(테스트) F1: 0.960\n"
     ]
    }
   ],
   "source": [
    "# 1-1\n",
    "dt_full = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "dt_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"= 제약없는 결정 트리 =\")\n",
    "\n",
    "y_pred_train = dt_full.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = dt_full.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffa093-d219-407b-bd34-6792699d0ee8",
   "metadata": {},
   "source": [
    "- max_depth는 결정트리의 깊이가 깊어짐에 따라 과대적합이 되는 것을 방지하고 새로운 데이터에 대한 예측 능력을 향상시킴.\n",
    "- max_depth를 너무 작게 설정하면 과소적합 될 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d12db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 가지치기한 결정 트리 =\n",
      "(학습) 정확도: 0.965\n",
      "(학습) F1: 0.971\n",
      "(테스트) 정확도: 0.912\n",
      "(테스트) F1: 0.931\n"
     ]
    }
   ],
   "source": [
    "dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=1)\n",
    "dt_pruned.fit(X_train, y_train)\n",
    "\n",
    "print(\"= 가지치기한 결정 트리 =\")\n",
    "\n",
    "y_pred_train = dt_pruned.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = dt_pruned.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544668e",
   "metadata": {},
   "source": [
    "## 2. 랜덤 포레스트\n",
    "- 랜덤 포레스트 모델을 학습하고, 학습 및 테스트 데이터 각각에 대해 정확도 및 F1을 측정합니다.\n",
    "- 2-1. 불순도 지표는 'gini', 트리 개수는 500으로 지정합니다.\n",
    "- 2-2. 불순도 지표는 'gini', 트리 개수는 50으로 지정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc4812-4b98-4f10-8d9d-7e3b935c5be0",
   "metadata": {},
   "source": [
    "#### ppt 11 - 결정 트리 응용: 랜덤 포레스트(Random Forest)\n",
    "- RandomForestClassifier: 결정 트리의 앙상블\n",
    "    - 과적합을 줄이고 일반화 성능 향상\n",
    "    - 하이퍼 파라미터 튜닝이 간단함\n",
    "        - 하이퍼 파라미터: 트리 개수 k가 성능에 영향을 주는 것. 중요하게 고려됨\n",
    "- n_estimator: 결정 트리의 개수\n",
    "    - 일반적으로 n_estimator을 늘릴수록 랜덤 포레스트의 성능이 향상될 수 있음\n",
    "    - 결정 트리가 많아질수록 모델의 복잡도가 증가하고 학습 시간이 더 오래 걸릴 수 있음 (과적합의 위험)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ca8bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 랜덤 포레스트 (트리 개수: 500) =\n",
      "(학습) 정확도: 1.000\n",
      "(학습) F1: 1.000\n",
      "(테스트) 정확도: 0.956\n",
      "(테스트) F1: 0.966\n"
     ]
    }
   ],
   "source": [
    "forest_500 = RandomForestClassifier(n_estimators=500, criterion='gini', random_state=1)\n",
    "forest_500.fit(X_train, y_train)\n",
    "\n",
    "print(\"= 랜덤 포레스트 (트리 개수: 500) =\")\n",
    "\n",
    "y_pred_train = forest_500.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = forest_500.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bde6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 랜덤 포레스트 (트리 개수: 50) =\n",
      "(학습) 정확도: 1.000\n",
      "(학습) F1: 1.000\n",
      "(테스트) 정확도: 0.956\n",
      "(테스트) F1: 0.966\n"
     ]
    }
   ],
   "source": [
    "forest_50 = RandomForestClassifier(n_estimators=50, criterion='gini', random_state=1)\n",
    "forest_50.fit(X_train, y_train)\n",
    "\n",
    "print(\"= 랜덤 포레스트 (트리 개수: 50) =\")\n",
    "\n",
    "y_pred_train = forest_50.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = forest_50.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4dbeb",
   "metadata": {},
   "source": [
    "## 3. 보팅 앙상블\n",
    "- 개별 모델을 로지스틱 회귀, KNN, 랜덤 포레스트(트리 개수 50, 불순도 지표 'gini')로 사용하는 보팅 앙상블 모델을 학습합니다. 학습한 모델을 이용해 테스트 데이터에 성능을 평가합니다. 랜덤 포레스트 모델은 2-2 에서 구현한 모델을 사용합니다.\n",
    "- 3.1. logistic regression 모델을 학습합니다.\n",
    "- 3.2. KNN 모델을 학습합니다. 이웃의 수는 8 입니다.\n",
    "- 3.3. 보팅 앙상블 모델을 학습합니다. 소프트 보팅을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d429b2-eefb-4bca-8f69-6701d1178b36",
   "metadata": {},
   "source": [
    "#### ppt 13, 16 참조\n",
    "- <b>보팅 앙상블(voting ensemble)</b>: 여러 개의 다른 머신러닝 모델을 결합하여 최종 예측을 만들고 많은 선택을 받은 클래스 레이블을 선택하는 방법 (== 다수결 방식의 머신러닝 구현)\n",
    "    - <b>로지스틱 회귀</b>: 선형 회귀를 분류 문제에 적용\n",
    "        - 주로 이진 분류. 클래스에 속할 확률을 추정하는 방식\n",
    "        - 간단, 해석이 쉬움, 과적합 방지하기 위해 정규화 기법\n",
    "        - 선형 결정 경계만을 학습할 수 있음. 복잡한 패턴 잡아내기 어려움\n",
    "    - <b>KNN(K-Nearest Neighbors)</b>: 지도 학습 알고리즘, 새로운 데이터를 예측할 때 가장 가까운 이웃 데이터의 클래스 사용하여 예측\n",
    "        - 인스턴스 기반 학습 방법. 데이터의 군집을 이용하여 예측\n",
    "        - 간단, 직관적인 모델, 비선형 결정 경계 학습 가능\n",
    "        - 테스트 데이터가 많으면 예측 속도가 느려짐\n",
    "    - <b>소프트 보팅</b>: 다수의 분류기가 예측한 확률을 평균하여 최종 예측을 결정하는 방식\n",
    "        - 각 분류기가 예측한 확률을 더하여 평균 내고, 가장 높은 평균 확률을 가지는 클래스 선택\n",
    "        - 하드 보팅보다 유연하고 확률적인 예측 제공, 정확한 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70fc5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 로지스틱 회귀 =\n",
      "(학습) 정확도: 0.949\n",
      "(학습) F1: 0.960\n",
      "(테스트) 정확도: 0.956\n",
      "(테스트) F1: 0.966\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=1)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"= 로지스틱 회귀 =\")\n",
    "\n",
    "y_pred_train = lr_clf.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = lr_clf.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32187d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= KNN =\n",
      "(학습) 정확도: 0.934\n",
      "(학습) F1: 0.948\n",
      "(테스트) 정확도: 0.947\n",
      "(테스트) F1: 0.959\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"= KNN =\")\n",
    "\n",
    "y_pred_train = knn_clf.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = knn_clf.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3dda078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Voting 분류기 =\n",
      "(학습) 정확도: 0.978\n",
      "(학습) F1: 0.983\n",
      "(테스트) 정확도: 0.947\n",
      "(테스트) F1: 0.959\n"
     ]
    }
   ],
   "source": [
    "vo_clf = VotingClassifier(estimators=[('lr', lr_clf), ('knn', knn_clf), ('rf', forest_50)], voting='soft')\n",
    "vo_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"= Voting 분류기 =\")\n",
    "\n",
    "y_pred_train = vo_clf.predict(X_train)\n",
    "print('(학습) 정확도: %.3f' % accuracy_score(y_train, y_pred_train))\n",
    "print('(학습) F1: %.3f' % f1_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred_test = vo_clf.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_test, y_pred_test))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d36428",
   "metadata": {},
   "source": [
    "## 4. 하이퍼파라미터 최적화\n",
    "- 학습 데이터에 대해 10-fold CV 기반 Grid Search를 수행합니다. scoring 기준은 roc_auc 입니다.\n",
    "- Logistic Regression 대상 하이퍼파라미터는 C 이며, 후보 값은 1, 0.1, 0.01 입니다.\n",
    "- KNN 대상 하이퍼파라미터는 n_neighbors 이며, 후보 값은 4, 6, 8 입니다.\n",
    "- Random Forest 대상 하이퍼파라미터는 num_estimators 이며, 후보 값은 50, 100, 500 입니다.\n",
    "- 최적 하이퍼파라미터를 이용해 테스트 데이터에 예측을 수행하고, 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186acc39-8633-4792-8651-e4662a0d6cac",
   "metadata": {},
   "source": [
    "<b>하이퍼파라미터 튜닝을 위해 투표 앙상블 분류기의 하이퍼파라미터를 확인한다.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2c26f2-e789-4ad0-8ae5-89fadc313002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimators': [('lr', LogisticRegression(random_state=1)),\n",
       "  ('knn', KNeighborsClassifier(n_neighbors=8)),\n",
       "  ('rf', RandomForestClassifier(n_estimators=50, random_state=1))],\n",
       " 'flatten_transform': True,\n",
       " 'n_jobs': None,\n",
       " 'verbose': False,\n",
       " 'voting': 'soft',\n",
       " 'weights': None,\n",
       " 'lr': LogisticRegression(random_state=1),\n",
       " 'knn': KNeighborsClassifier(n_neighbors=8),\n",
       " 'rf': RandomForestClassifier(n_estimators=50, random_state=1),\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': 1,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 8,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform',\n",
       " 'rf__bootstrap': True,\n",
       " 'rf__ccp_alpha': 0.0,\n",
       " 'rf__class_weight': None,\n",
       " 'rf__criterion': 'gini',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'sqrt',\n",
       " 'rf__max_leaf_nodes': None,\n",
       " 'rf__max_samples': None,\n",
       " 'rf__min_impurity_decrease': 0.0,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__min_weight_fraction_leaf': 0.0,\n",
       " 'rf__n_estimators': 50,\n",
       " 'rf__n_jobs': None,\n",
       " 'rf__oob_score': False,\n",
       " 'rf__random_state': 1,\n",
       " 'rf__verbose': 0,\n",
       " 'rf__warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vo_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bdbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990 +/- 0.00 {'knn__n_neighbors': 4, 'lr__C': 1, 'rf__n_estimators': 50}\n",
      "0.990 +/- 0.00 {'knn__n_neighbors': 4, 'lr__C': 1, 'rf__n_estimators': 100}\n",
      "0.990 +/- 0.00 {'knn__n_neighbors': 4, 'lr__C': 1, 'rf__n_estimators': 500}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 4, 'lr__C': 0.1, 'rf__n_estimators': 50}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 4, 'lr__C': 0.1, 'rf__n_estimators': 100}\n",
      "0.989 +/- 0.01 {'knn__n_neighbors': 4, 'lr__C': 0.1, 'rf__n_estimators': 500}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 4, 'lr__C': 0.01, 'rf__n_estimators': 50}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 4, 'lr__C': 0.01, 'rf__n_estimators': 100}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 4, 'lr__C': 0.01, 'rf__n_estimators': 500}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 6, 'lr__C': 1, 'rf__n_estimators': 50}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 6, 'lr__C': 1, 'rf__n_estimators': 100}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 6, 'lr__C': 1, 'rf__n_estimators': 500}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 6, 'lr__C': 0.1, 'rf__n_estimators': 50}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 6, 'lr__C': 0.1, 'rf__n_estimators': 100}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 6, 'lr__C': 0.1, 'rf__n_estimators': 500}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 6, 'lr__C': 0.01, 'rf__n_estimators': 50}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 6, 'lr__C': 0.01, 'rf__n_estimators': 100}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 6, 'lr__C': 0.01, 'rf__n_estimators': 500}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 1, 'rf__n_estimators': 50}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 1, 'rf__n_estimators': 100}\n",
      "0.990 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 1, 'rf__n_estimators': 500}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 8, 'lr__C': 0.1, 'rf__n_estimators': 50}\n",
      "0.988 +/- 0.01 {'knn__n_neighbors': 8, 'lr__C': 0.1, 'rf__n_estimators': 100}\n",
      "0.989 +/- 0.01 {'knn__n_neighbors': 8, 'lr__C': 0.1, 'rf__n_estimators': 500}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 0.01, 'rf__n_estimators': 50}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 0.01, 'rf__n_estimators': 100}\n",
      "0.989 +/- 0.00 {'knn__n_neighbors': 8, 'lr__C': 0.01, 'rf__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'lr__C':[1, 0.1, 0.01],\n",
    "          'knn__n_neighbors': [4, 6, 8],\n",
    "          'rf__n_estimators': [50, 100, 500]}\n",
    "\n",
    "grid = GridSearchCV(estimator=vo_clf, param_grid=params, cv=10, scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_['mean_test_score'][r], \n",
    "             grid.cv_results_['std_test_score'][r] / 2.0, \n",
    "             grid.cv_results_['params'][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49cc855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 매개변수: {'knn__n_neighbors': 4, 'lr__C': 1, 'rf__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print('최적의 매개변수: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2c5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.99\n"
     ]
    }
   ],
   "source": [
    "print('정확도: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13aad11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(테스트) 정확도: 0.947\n",
      "(테스트) F1: 0.959\n"
     ]
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('(테스트) 정확도: %.3f' % accuracy_score(y_true=y_test,y_pred=y_test_pred))\n",
    "print('(테스트) F1: %.3f' % f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4627c-a298-43ab-bdc4-8df21df9ff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb_conda_kernels",
   "language": "python",
   "name": "nb_conda_kernels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
